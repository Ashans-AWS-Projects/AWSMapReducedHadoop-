<!-- Markdown with Embedded HTML & CSS -->
<div style="background-color: #f7f9fc; padding: 20px; border-radius: 10px;">
    <h1 align="center" style="font-family: 'Arial', sans-serif; color: #2c3e50;">Hadoop Batch Data Processing with MapReduce, Pig, and Hive</h1>
</div>

<div align="center">
    <img src="https://user-images.githubusercontent.com/yourprofile/hadoop-banner.png" alt="Hadoop Banner" style="width: 80%; border-radius: 10px;">
</div>

<br>

## 🌟 Overview

This project showcases various batch data processing techniques using Hadoop's ecosystem, including MapReduce, Pig, and Hive, to analyze bigram data. The analysis focuses on extracting insights from a large dataset, such as identifying the most common bigrams over time, calculating average occurrences, and more.

## 📋 Table of Contents

- [Introduction](#introduction)
- [Technologies Used](#technologies-used)
- [Setup and Installation](#setup-and-installation)
- [Tasks Overview](#tasks-overview)
- [Results](#results)
- [Screenshots](#screenshots)
- [Contributors](#contributors)
- [License](#license)

## 🚀 Introduction

In this project, we set up a Hadoop cluster using Amazon EMR, followed by executing various data processing tasks. The tasks include implementing custom MapReduce jobs, writing Pig scripts, and running Hive queries to gain insights from a large corpus of text data.

## 🛠️ Technologies Used

<div style="display: flex; justify-content: space-around; padding: 10px;">
    <img src="https://img.shields.io/badge/Apache%20Hadoop-66CCFF?style=for-the-badge&logo=apache&logoColor=white" alt="Apache Hadoop">
    <img src="https://img.shields.io/badge/Amazon%20EMR-FF9900?style=for-the-badge&logo=amazonaws&logoColor=white" alt="Amazon EMR">
    <img src="https://img.shields.io/badge/Apache%20Pig-FB8333?style=for-the-badge&logo=apache&logoColor=white" alt="Apache Pig">
    <img src="https://img.shields.io/badge/Apache%20Hive-FF6F00?style=for-the-badge&logo=apache&logoColor=white" alt="Apache Hive">
    <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
</div>

## 🛠️ Setup and Installation

### Prerequisites

- **AWS Account**: To create and manage EMR clusters.
- **Python**: Install Python 3.x.
- **mrjob**: Install using pip.
  ```bash
  pip install mrjob

Using Map reduced with pig, hadoop and SQL
